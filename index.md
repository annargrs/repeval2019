---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
# layout: home
title: The Third Workshop on Evaluating Vector Space Representations for NLP
---

# The Third Workshop on Evaluating Vector Space Representations for NLP

General-purpose dense word embeddings have come a long way since the beginning of their boom in 2013, and they are still the most widely used way of representing words in both industrial and academic NLP systems. However, the issue of intrinsic metrics that be predictive of performance on downstream tasks is far from being solved. Since the last RepEval there also appeared a number of probing tasks and large extrinsic evaluation datasets for sentence representations, but there is still much to learn about what features make a compositional representation successful. Last but not the least, there are no established intrinsic methods for newer kinds of representations such as ELMO, BERT, or box embeddings. 

The third edition of RepEval aims to foster discussion of the above issues, and to support the search for high-quality general purpose representation learning techniques for NLP. Furthermore, we hope to encourage interdisciplinary dialogue by welcoming diverse perspectives on the above issues: submissions may focus on properties of embedding space, performance analysis for various downstream tasks, as well as approaches based on linguistic and psychological data. In particular, experts from the latter fields are encouraged to contribute analysis of claims previously made in NLP community.

RepEval 2019 will invite submissions including, but not limited to the following issues: 

* approaches to intrinsic and extrinsic evaluation of all kinds of representations, esp. contextualized;
* evaluation motivated by linguistic, psycholinguistic or neurological evidence, and its predictive power;%, and interpretability of meaning representations vs evaluation on downstream tasks;
* the (un)stability of vector representations, best practices for reproducible and reliable experiments;
* evaluation of representations at subword level, especially for morphologically complex languages;
* evaluation of phrase, sentence, paragraph and document-level representations: evidence of compositionality, further diagnostic tests, and how much the preservation of abstract syntactic information actually contributes to performance;
* formal analysis of properties of embedding spaces and their impact on downstream tasks;
* the effect of representations vs other elements of pipeline in extrinsic evaluations;
* validation of evaluation methodology and findings in cross-lingual studies;
* specialized vs general-purpose representations, and whether the latter have inherent limits in downstream tasks;
* internal states of end-to-end systems as meaning representations, and ways to make more sense of them.

The workshop will accept submissions through two tracks: research and shared task. The research track will showcase proposals for new evaluation techniques for old and new representations; the submissions are expected to experimentally demonstrate the benefits of the new approach. We also invite critical analysis and/or negative results for the existing approaches. We welcome both theoretical analysis (especially from experts in other domains such as linguistics or psychology) and methodological caveats (reproducibility, parameters, the issue of attribution of results to the representation or the whole system).