---
title: Program
permalink: /program/
---

## <span class="time"> The program of the workshop </span>

The workshop will be held in Nicollet A 1-2 of Hyatt Regency in Minneapolis. 

Poster session location: Hyatt Exhibit Hall on the Main Level.

The floor plan is available [here](2019-NAACL-Minneapolis-Floorplans.pdf).


<span class="time"> 09:00 - 09:30</span> Opening remarks. Evaluation of meaning representations for NLP: directions and milestones. 

<span class="time"> 09:30 - 10:30</span> <span class="hl">How well do neural NLP systems generalize?</span> <br/> Invited talk by [Tal Linzen](http://tallinzen.net/) (Johns Hopkins University) 

> Neural networks have rapidly become central to NLP systems. While such systems often perform well on typical test set examples, their generalization abilities are often poorly understood. In this talk, I will demonstrate how experimental paradigms from psycholinguistics can help us characterize the gaps between the abilities of neural systems and those of humans, by focusing on interpretable axes of generalization from the training set rather than on average test set performance. I will show that recurrent neural network (RNN) language models are able to process syntactic dependencies in typical sentences with considerable success, but when evaluated on more complex syntactically controlled materials, their error rate increases sharply. Likewise, neural systems trained to perform natural language inference generalize much more poorly than their test set performance would suggest.

*Speaker bio*: Tal Linzen is an Assistant Professor of Cognitive Science and Computer Science at Johns Hopkins University. He directs the Computation and Psycholinguistics Lab, which develops computational models of human language comprehension and acquisition, as well as methods for interpreting, evaluating and extending neural network models for natural language processing. Dr. Linzen is one of the co-organizers of the BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP (EMNLP 2018, ACL 2019).

<span class="time"> 10:30 - 11:00</span> Coffee break 

<span class="time"> 11:00 - 12:00</span> <span class="hl">Invited talk: Kristina Toutanova* (Google AI)</span> <br/> (TBA) 


<span class="time"> 11:00 - 12:00</span> <span class="hl">
Learning and evaluating generalizable vector space representations of texts</span> <br/> Invited talk by [Kristina Toutanova](http://kristinatoutanova.com/) (Google AI) 

> I will talk about our recent and forthcoming work on pre-training vector space representations of texts of multiple granularities and in different contexts.  I will present evaluation on end-user tasks and an analysis of the component representations on probing tasks. Finally, I will motivate the need for new kinds of textual representations and ways to measure their ability to generalize across tasks.

*Speaker bio*: Kristina Toutanova is a research scientist at Google Research in the  Language team in Seattle and an affiliate faculty at the University of Washington. She obtained her Ph.D. from Stanford University with Christopher Manning. Prior to joining Google in 2017, she was a researcher at Microsoft Research, Redmond. Kristina focuses on modeling the structure of natural language using machine learning, most recently in the areas of representation learning, question answering, information retrieval, semantic parsing, and knowledge base completion. Kristina is a past co-editor in chief of TACL and was a program co-chair for ACL 2014.

<span class="time"> 12:00 - 13:30</span> Lunch 

<span class="time"> 13.30 - 14.45</span> Oral session

 - <span class="time"> 13.30 - 13.45</span> <span class="hl">Neural Vector Conceptualization for Word Vector Space Interpretation</span> ([PDF](https://www.aclweb.org/anthology/W19-2001))<br/>
    Robert Schwarzenberg, Lisa Raithel and David Harbecke 

 - <span class="time"> 13.45 - 14.00</span> <span class="hl">Characterizing the Impact of Geometric Properties of Word Embeddings on Task Performance</span> ([PDF](https://www.aclweb.org/anthology/W19-2002))<br/>
    Brendan Whitaker, Denis Newman-Griffis, Aparajita Haldar, Hakan Ferhatosmanoglu and Eric Fosler-Lussier 

 - <span class="time"> 14.00 - 14.15</span> <span class="hl">The Influence of Down-Sampling Strategies on SVD Word Embedding Stability</span> ([PDF](https://www.aclweb.org/anthology/W19-2003))<br/>
    Johannes Hellrich, Bernd Kampe and Udo Hahn 

 - <span class="time"> 14.15 - 14.30</span> <span class="hl">How well do Embedding Models capture Non-compositionality? A View from Multiword Expressions</span> ([PDF](https://www.aclweb.org/anthology/W19-2004))<br/>
    Navnita Nandakumar, Bahar Salehi and Timothy Baldwin 

 - <span class="time"> 14.30 - 14.45</span> <span class="hl">Measuring Semantic Abstraction of Multilingual NMT with Paraphrase Recognition and Generation Tasks</span> ([PDF](https://www.aclweb.org/anthology/W19-2005))<br/>
   JÃ¶rg Tiedemann and Yves Scherrer 

<span class="time"> 14:45 - 15:00</span> 1-minute poster madness  

<span class="time"> 15.00 - 15.45</span> Poster session

 - <span class="hl">SWOW-8500: Word Association task for Intrinsic Evaluation of Word Embeddings</span> ([PDF](https://www.aclweb.org/anthology/W19-2006)) <br/>
    Avijit Thawani, Biplav Srivastava and Anil Singh 

- <span class="hl">Classification of Semantic Paraphasias: Optimization of a Word Embedding Model</span> ([PDF](https://www.aclweb.org/anthology/W19-2007))<br/>
   Katy McKinney-Bock and Steven Bedrick 

 - <span class="hl">CODAH: An Adversarially Authored Question-Answer Dataset for Common Sense</span> ([PDF](https://www.aclweb.org/anthology/W19-2008))<br/>
    Michael Chen, Mike D'Arcy, Alisa Liu, Jared Fernandez and  Doug Downey

 - <span class="hl">Syntactic Interchangeability in Word Embedding Models</span> ([PDF](https://www.aclweb.org/anthology/W19-2009))<br/>
    Daniel Hershcovich, Assaf Toledo, Alon Halfon and Noam Slonim 

 - <span class="hl">Evaluation of Morphological Embeddings for English and Russian Languages</span> ([PDF](https://www.aclweb.org/anthology/W19-2010))<br/>
    Vitaly Romanov and Albina Khusainova 

 - <span class="hl">Probing Biomedical Embeddings from Language Models</span> ([PDF](https://www.aclweb.org/anthology/W19-2011))<br/>
    Qiao Jin, Bhuwan Dhingra, William Cohen and Xinghua Lu 

 - <span class="hl">Dyr bul shchyl. Proxying Sound Symbolism with Word Embeddings</span> ([PDF](https://www.aclweb.org/anthology/W19-2012))<br/>
    Ivan Yamshchikov, Viascheslav Shibaev and Alexey Tikhonov 

 - <span class="hl">Multi-Context Term Embeddings: the Use Case of Corpus-based Term Set Expansion</span> ([PDF](https://www.aclweb.org/anthology/W19-2013))<br/>
    Jonathan Mamou, Oren Pereg, Moshe Wasserblat and Ido Dagan 

<span class="time"> 15:45 - 16:00</span> Coffee break 

<span class="time"> 16.00 - 17.15</span> <span class="hl">A linguist, an NLP engineer, and a psycholinguist walk into a bar...</span> Panel discussion with Sam Bowman, Ryan Cotterell, Barry Devereux, Allyson Ettinger, and Tal Linzen. 

<span class="time"> 17:15 - 17:30</span> Closing remarks 